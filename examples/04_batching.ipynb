{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Engine on http://localhost:50001 Running LLMstudio Tracking on http://localhost:50002 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llmstudio import LLM\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LLM(\"openai/gpt-3.5-turbo\")\n",
    "llm = LLM(\"vertexai/gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"What's your name?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"What's the weather like?\",\n",
    "    \"Can you sing a song?\",\n",
    "    \"Tell me about yourself.\",\n",
    "    \"What's your favorite color?\",\n",
    "    \"Do you have any pets?\",\n",
    "    \"What's your favorite food?\",\n",
    "    \"What's your favorite book?\",\n",
    "    \"Who is your favorite author?\",\n",
    "    \"What's your favorite movie?\",\n",
    "    \"Who is your favorite actor?\",\n",
    "    \"What's your favorite song?\",\n",
    "    \"Who is your favorite singer?\",\n",
    "    \"What's your favorite sport?\",\n",
    "    \"Who is your favorite athlete?\",\n",
    "    \"What's your favorite team?\",\n",
    "    \"What's your favorite city?\",\n",
    "    \"What's your favorite country?\",\n",
    "    \"What's your favorite place?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting chat responses: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "responses = llm.batch_chat(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletion(id='680121c9-1e22-48aa-9590-e65491905ca4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I don't have a name. I'm a large language model, and I'm here to assist you with your questions and requests. ðŸ˜Š \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282537, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your name?\", chat_output=\"I don't have a name. I'm a large language model, and I'm here to assist you with your questions and requests. ðŸ˜Š \\n\", context=[{'role': 'user', 'content': \"What's your name?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282537.833985, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 30, 'total_tokens': 35, 'cost_usd': 3.325e-05, 'latency_s': 3.6737987995147705, 'time_to_first_token_s': 3.6732778549194336, 'inter_token_latency_s': 9.140968322753906e-05, 'tokens_per_second': 1.6331868802375542}),\n",
       " ChatCompletion(id='2bae56a2-dd7b-4123-85df-67f4dadcc6c8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything! ðŸ˜œ \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282536, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Tell me a joke.', chat_output=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything! ðŸ˜œ \\n\", context=[{'role': 'user', 'content': 'Tell me a joke.'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282536.147192, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 16, 'total_tokens': 21, 'cost_usd': 1.8549999999999997e-05, 'latency_s': 1.9874858856201172, 'time_to_first_token_s': 1.986732006072998, 'inter_token_latency_s': 0.00011534690856933594, 'tokens_per_second': 3.0188893633968803}),\n",
       " ChatCompletion(id='772fdb57-0321-4a08-8606-bed1ab8c1bf4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I do not have access to real-time information, including weather conditions. To get the current weather, I recommend checking a weather app or website for your location. \\n', role='assistant', function_call=None, tool_calls=None))], created=1725282536, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's the weather like?\", chat_output='I do not have access to real-time information, including weather conditions. To get the current weather, I recommend checking a weather app or website for your location. \\n', context=[{'role': 'user', 'content': \"What's the weather like?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282536.151859, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 33, 'total_tokens': 39, 'cost_usd': 3.674999999999999e-05, 'latency_s': 1.9979071617126465, 'time_to_first_token_s': 1.9971439838409424, 'inter_token_latency_s': 7.772445678710938e-05, 'tokens_per_second': 4.004190061134892}),\n",
       " ChatCompletion(id='dd92b2c4-d4b4-45b7-957f-e8afdce5225b', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I can't actually sing! I'm a language model, so I don't have a voice. I can write lyrics, though. \\n\\nWhat kind of song would you like me to write?  \\n\\nDo you have a theme in mind? \\n  - A love song? \\n  - A funny song? \\n  - A sad song?\\n  - Something else entirely? \\n\\nTell me more and I'll do my best to create something for you! ðŸŽ¤ \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282539, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Can you sing a song?', chat_output=\"I can't actually sing! I'm a language model, so I don't have a voice. I can write lyrics, though. \\n\\nWhat kind of song would you like me to write?  \\n\\nDo you have a theme in mind? \\n  - A love song? \\n  - A funny song? \\n  - A sad song?\\n  - Something else entirely? \\n\\nTell me more and I'll do my best to create something for you! ðŸŽ¤ \\n\", context=[{'role': 'user', 'content': 'Can you sing a song?'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282539.557605, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 95, 'total_tokens': 101, 'cost_usd': 0.00010184999999999998, 'latency_s': 1.7107610702514648, 'time_to_first_token_s': 1.0178632736206055, 'inter_token_latency_s': 0.06083716045726429, 'tokens_per_second': 7.014421948610345}),\n",
       " ChatCompletion(id='1a966821-65d7-4276-8bf0-b3cc7f631369', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I am a large language model, trained by Google.\\n\\n**Here are some key things about me:**\\n\\n* **I'm trained on a massive dataset of text and code:** This allows me to generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\\n* **I'm constantly learning:** I am always being updated with new information and data, which helps me improve my abilities and provide more accurate and relevant responses.\\n* **I'm designed to be helpful:** My purpose is to assist you with your tasks and answer your questions to the best of my ability. \\n* **I'm still under development:** I am constantly being improved and refined, and I am always learning new things.\\n\\n**What I can do for you:**\\n\\n* Provide information on a wide range of topics\\n* Generate creative content, such as stories, poems, and scripts\\n* Translate languages\\n* Answer your questions in a comprehensive and informative way\\n* Help you with tasks like writing emails, summarizing articles, and generating code\\n\\n**My limitations:**\\n\\n* **I am not sentient or conscious:** I am a computer program, and I do not have my own thoughts or feelings.\\n* **I can sometimes make mistakes:** As a language model, I am still under development and can make mistakes. \\n* **I am not a replacement for human interaction:** While I can provide information and assistance, I am not a substitute for human connection.\\n\\n**How to get the most out of me:**\\n\\n* **Be specific with your requests:** The more specific you are, the better I can understand your needs and provide you with relevant information.\\n* **Provide context:** If you have any background information or specific instructions, please share them with me.\\n* **Be patient:** I am constantly learning and improving, and I may not always be able to provide the perfect answer. \\n\\nI'm here to help you, so feel free to ask me anything! \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282537, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Tell me about yourself.', chat_output=\"I am a large language model, trained by Google.\\n\\n**Here are some key things about me:**\\n\\n* **I'm trained on a massive dataset of text and code:** This allows me to generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\\n* **I'm constantly learning:** I am always being updated with new information and data, which helps me improve my abilities and provide more accurate and relevant responses.\\n* **I'm designed to be helpful:** My purpose is to assist you with your tasks and answer your questions to the best of my ability. \\n* **I'm still under development:** I am constantly being improved and refined, and I am always learning new things.\\n\\n**What I can do for you:**\\n\\n* Provide information on a wide range of topics\\n* Generate creative content, such as stories, poems, and scripts\\n* Translate languages\\n* Answer your questions in a comprehensive and informative way\\n* Help you with tasks like writing emails, summarizing articles, and generating code\\n\\n**My limitations:**\\n\\n* **I am not sentient or conscious:** I am a computer program, and I do not have my own thoughts or feelings.\\n* **I can sometimes make mistakes:** As a language model, I am still under development and can make mistakes. \\n* **I am not a replacement for human interaction:** While I can provide information and assistance, I am not a substitute for human connection.\\n\\n**How to get the most out of me:**\\n\\n* **Be specific with your requests:** The more specific you are, the better I can understand your needs and provide you with relevant information.\\n* **Provide context:** If you have any background information or specific instructions, please share them with me.\\n* **Be patient:** I am constantly learning and improving, and I may not always be able to provide the perfect answer. \\n\\nI'm here to help you, so feel free to ask me anything! \\n\", context=[{'role': 'user', 'content': 'Tell me about yourself.'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282537.828429, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 399, 'total_tokens': 404, 'cost_usd': 0.0004207, 'latency_s': 3.6699392795562744, 'time_to_first_token_s': 2.0165469646453857, 'inter_token_latency_s': 0.07743120193481445, 'tokens_per_second': 5.994649590676601}),\n",
       " Exception(\"'NoneType' object is not subscriptable\"),\n",
       " ChatCompletion(id='333cc59b-3b82-44ba-b6de-77af9bf6b1d0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As a large language model, I am not capable of having pets. I exist only as a computer program and do not have a physical body.  \\n\\nHowever, I can access and process information about pets, and I can tell you many interesting facts about them! Do you have any questions about pets? ðŸ¾ \\n', role='assistant', function_call=None, tool_calls=None))], created=1725282536, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Do you have any pets?', chat_output='As a large language model, I am not capable of having pets. I exist only as a computer program and do not have a physical body.  \\n\\nHowever, I can access and process information about pets, and I can tell you many interesting facts about them! Do you have any questions about pets? ðŸ¾ \\n', context=[{'role': 'user', 'content': 'Do you have any pets?'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282536.1629708, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 64, 'total_tokens': 70, 'cost_usd': 6.929999999999999e-05, 'latency_s': 2.005898952484131, 'time_to_first_token_s': 2.005185127258301, 'inter_token_latency_s': 4.427773611886161e-05, 'tokens_per_second': 3.9882367903391636}),\n",
       " ChatCompletion(id='dcd9ac0c-ecc4-452a-a73d-54aa46fa4bac', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an AI, I don't have a physical body or the ability to eat. So I don't have a favorite food!  However, I can access and process information from the real world, including information about food. \\n\\nWhat's your favorite food? I'd love to learn more about it! \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282537, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your favorite food?\", chat_output=\"As an AI, I don't have a physical body or the ability to eat. So I don't have a favorite food!  However, I can access and process information from the real world, including information about food. \\n\\nWhat's your favorite food? I'd love to learn more about it! \\n\", context=[{'role': 'user', 'content': \"What's your favorite food?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282537.838346, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 62, 'total_tokens': 68, 'cost_usd': 6.72e-05, 'latency_s': 3.6869590282440186, 'time_to_first_token_s': 3.6866090297698975, 'inter_token_latency_s': 3.3325619167751735e-05, 'tokens_per_second': 2.712262307065203}),\n",
       " ChatCompletion(id='a10e41ea-1fa9-4e30-ba24-ca0ca2920b44', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As a language model, I don\\'t have personal preferences or the capacity to \"read\" and enjoy books like humans do. I can\\'t form opinions or have favorites. \\n\\nHowever, I can access and process information from countless books, and I\\'m happy to help you find something you might enjoy! To give you a good recommendation, could you tell me:\\n\\n* **What kind of books do you usually like to read?** (e.g., fantasy, sci-fi, romance, historical fiction, non-fiction, etc.)\\n* **Do you have any favorite authors?**\\n* **What are some of your favorite books?**\\n\\nThe more information you give me, the better I can tailor a recommendation just for you! ðŸ˜Š \\n', role='assistant', function_call=None, tool_calls=None))], created=1725282536, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your favorite book?\", chat_output='As a language model, I don\\'t have personal preferences or the capacity to \"read\" and enjoy books like humans do. I can\\'t form opinions or have favorites. \\n\\nHowever, I can access and process information from countless books, and I\\'m happy to help you find something you might enjoy! To give you a good recommendation, could you tell me:\\n\\n* **What kind of books do you usually like to read?** (e.g., fantasy, sci-fi, romance, historical fiction, non-fiction, etc.)\\n* **Do you have any favorite authors?**\\n* **What are some of your favorite books?**\\n\\nThe more information you give me, the better I can tailor a recommendation just for you! ðŸ˜Š \\n', context=[{'role': 'user', 'content': \"What's your favorite book?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282536.134807, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 147, 'total_tokens': 153, 'cost_usd': 0.00015644999999999998, 'latency_s': 1.9793319702148438, 'time_to_first_token_s': 1.0310051441192627, 'inter_token_latency_s': 0.07071076906644382, 'tokens_per_second': 7.073093453080733}),\n",
       " ChatCompletion(id='0a39fd23-da88-4172-a302-2b613d0c60eb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As a large language model, I don't have personal preferences like favorite authors. I can access and process information from a vast amount of text, including books, articles, and websites. \\n\\nTo help you find your favorite author, I need some more information. What kind of books do you enjoy? What are your favorite genres? Tell me a little about your reading preferences, and I can suggest some great authors for you! ðŸ˜Š \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282536, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Who is your favorite author?', chat_output=\"As a large language model, I don't have personal preferences like favorite authors. I can access and process information from a vast amount of text, including books, articles, and websites. \\n\\nTo help you find your favorite author, I need some more information. What kind of books do you enjoy? What are your favorite genres? Tell me a little about your reading preferences, and I can suggest some great authors for you! ðŸ˜Š \\n\", context=[{'role': 'user', 'content': 'Who is your favorite author?'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282536.167819, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 88, 'total_tokens': 94, 'cost_usd': 9.449999999999999e-05, 'latency_s': 2.0108449459075928, 'time_to_first_token_s': 2.010159969329834, 'inter_token_latency_s': 5.409452650282118e-05, 'tokens_per_second': 4.973033858404488}),\n",
       " Exception(\"'NoneType' object is not subscriptable\"),\n",
       " ChatCompletion(id='70fbcc16-a0ff-41ed-bbeb-899089451b6f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an AI, I don't have personal preferences like favorite actors. I can't experience emotions or form opinions like humans do. \\n\\nHowever, I can access and process information from the real world, including information about actors.  What kind of actors are you interested in? Maybe I can help you find some great movies or shows to watch! \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282537, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Who is your favorite actor?', chat_output=\"As an AI, I don't have personal preferences like favorite actors. I can't experience emotions or form opinions like humans do. \\n\\nHowever, I can access and process information from the real world, including information about actors.  What kind of actors are you interested in? Maybe I can help you find some great movies or shows to watch! \\n\", context=[{'role': 'user', 'content': 'Who is your favorite actor?'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282537.842106, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 70, 'total_tokens': 76, 'cost_usd': 7.56e-05, 'latency_s': 3.68772292137146, 'time_to_first_token_s': 3.6874098777770996, 'inter_token_latency_s': 2.8795666164822047e-05, 'tokens_per_second': 2.7117004756639935}),\n",
       " Exception(\"'NoneType' object is not subscriptable\"),\n",
       " ChatCompletion(id='1c805654-4e25-41bb-b350-a7be4ea089c1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an AI, I don't have personal preferences like favorite singers!  I can't listen to music or experience emotions the way humans do.  \\n\\nBut I can tell you about some very popular singers!  What kind of music do you like?  Maybe I can recommend some artists you'd enjoy. ðŸ˜„ \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282536, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Who is your favorite singer?', chat_output=\"As an AI, I don't have personal preferences like favorite singers!  I can't listen to music or experience emotions the way humans do.  \\n\\nBut I can tell you about some very popular singers!  What kind of music do you like?  Maybe I can recommend some artists you'd enjoy. ðŸ˜„ \\n\", context=[{'role': 'user', 'content': 'Who is your favorite singer?'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282536.156669, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 64, 'total_tokens': 70, 'cost_usd': 6.929999999999999e-05, 'latency_s': 2.0050570964813232, 'time_to_first_token_s': 2.004382848739624, 'inter_token_latency_s': 7.070435418023003e-05, 'tokens_per_second': 4.987389145949514}),\n",
       " ChatCompletion(id='fc075281-23e2-4b00-8650-6493f987a1dd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an AI, I don't have personal preferences like favorite sports. I can, however, tell you about many sports and their rules, history, and interesting facts. \\n\\nWhat kind of sports are you interested in? I can provide you with information about any sport you like!  \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282539, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your favorite sport?\", chat_output=\"As an AI, I don't have personal preferences like favorite sports. I can, however, tell you about many sports and their rules, history, and interesting facts. \\n\\nWhat kind of sports are you interested in? I can provide you with information about any sport you like!  \\n\", context=[{'role': 'user', 'content': \"What's your favorite sport?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282539.596948, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 57, 'total_tokens': 63, 'cost_usd': 6.194999999999999e-05, 'latency_s': 1.7501609325408936, 'time_to_first_token_s': 1.7498350143432617, 'inter_token_latency_s': 3.9577484130859375e-05, 'tokens_per_second': 4.571008214876305}),\n",
       " ChatCompletion(id='2709a0b3-9082-450f-8cbc-8c3b68d1b60a', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As a large language model, I don't have personal preferences like favorite athletes. I can access and process information from the real world through Google Search and keep my response consistent with search results.  \\n\\nTo find out who is a popular athlete, I can tell you that according to recent Google searches, **Lionel Messi** is a very popular athlete.  He is an Argentine professional footballer widely regarded as one of the greatest players of all time.\\n\\nDo you have a favorite athlete? I'd love to learn more about them! \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282539, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Who is your favorite athlete?', chat_output=\"As a large language model, I don't have personal preferences like favorite athletes. I can access and process information from the real world through Google Search and keep my response consistent with search results.  \\n\\nTo find out who is a popular athlete, I can tell you that according to recent Google searches, **Lionel Messi** is a very popular athlete.  He is an Argentine professional footballer widely regarded as one of the greatest players of all time.\\n\\nDo you have a favorite athlete? I'd love to learn more about them! \\n\", context=[{'role': 'user', 'content': 'Who is your favorite athlete?'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282539.5829551, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 108, 'total_tokens': 114, 'cost_usd': 0.00011549999999999999, 'latency_s': 1.7354931831359863, 'time_to_first_token_s': 1.7162952423095703, 'inter_token_latency_s': 5.680864507501776e-05, 'tokens_per_second': 6.914461040011892}),\n",
       " ChatCompletion(id='31a4bb7f-301c-4473-ae6c-d5b540663965', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As a large language model, I don't have personal preferences or feelings like having a favorite team.  I can't experience things like rooting for a team or feeling the excitement of a win. \\n\\nHowever, I can tell you about many different sports teams! What kind of team are you interested in?  Do you follow any sports leagues or have a favorite athlete? ðŸ˜Š \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282539, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your favorite team?\", chat_output=\"As a large language model, I don't have personal preferences or feelings like having a favorite team.  I can't experience things like rooting for a team or feeling the excitement of a win. \\n\\nHowever, I can tell you about many different sports teams! What kind of team are you interested in?  Do you follow any sports leagues or have a favorite athlete? ðŸ˜Š \\n\", context=[{'role': 'user', 'content': \"What's your favorite team?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282539.5929852, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 77, 'total_tokens': 83, 'cost_usd': 8.294999999999998e-05, 'latency_s': 1.7463030815124512, 'time_to_first_token_s': 1.746048927307129, 'inter_token_latency_s': 2.3894839816623265e-05, 'tokens_per_second': 5.726382840336699}),\n",
       " ChatCompletion(id='155c53c9-17a8-45d7-a235-668480039220', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an AI, I don't have personal preferences like favorite cities. I can't experience the world like humans do!  \\n\\nHowever, I can tell you about many cities based on different criteria. What are you interested in?  \\n\\n* **Do you want to know about a city with amazing history?** \\n* **Or maybe a vibrant cultural scene?**\\n* **Or perhaps a city with stunning natural beauty?** \\n\\nTell me what you're looking for, and I can share some amazing cities with you! \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282539, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your favorite city?\", chat_output=\"As an AI, I don't have personal preferences like favorite cities. I can't experience the world like humans do!  \\n\\nHowever, I can tell you about many cities based on different criteria. What are you interested in?  \\n\\n* **Do you want to know about a city with amazing history?** \\n* **Or maybe a vibrant cultural scene?**\\n* **Or perhaps a city with stunning natural beauty?** \\n\\nTell me what you're looking for, and I can share some amazing cities with you! \\n\", context=[{'role': 'user', 'content': \"What's your favorite city?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282539.588243, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 104, 'total_tokens': 110, 'cost_usd': 0.00011129999999999998, 'latency_s': 1.7401537895202637, 'time_to_first_token_s': 1.7396748065948486, 'inter_token_latency_s': 3.9382414384321734e-05, 'tokens_per_second': 6.895942227789093}),\n",
       " ChatCompletion(id='fefb3ce7-1110-4e3d-ac23-b47628806d04', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an AI, I don't have personal preferences like favorite countries. I can provide you with information about any country you're interested in.  \\n\\nWhat are you looking to learn about? Perhaps you could tell me about a country that you find interesting and we can explore it together! ðŸŒŽ ðŸ˜Š \\n\", role='assistant', function_call=None, tool_calls=None))], created=1725282536, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your favorite country?\", chat_output=\"As an AI, I don't have personal preferences like favorite countries. I can provide you with information about any country you're interested in.  \\n\\nWhat are you looking to learn about? Perhaps you could tell me about a country that you find interesting and we can explore it together! ðŸŒŽ ðŸ˜Š \\n\", context=[{'role': 'user', 'content': \"What's your favorite country?\"}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1725282536.171442, parameters={'top_p': 1, 'top_k': 1, 'temperature': 1, 'max_output_tokens': 8192, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 62, 'total_tokens': 68, 'cost_usd': 6.72e-05, 'latency_s': 2.0139100551605225, 'time_to_first_token_s': 2.0134971141815186, 'inter_token_latency_s': 5.354200090680804e-05, 'tokens_per_second': 3.972372042882692}),\n",
       " Exception(\"'NoneType' object is not subscriptable\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear chat calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:20<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "sync_responses = []\n",
    "from tqdm import tqdm\n",
    "for input in tqdm(inputs):\n",
    "    sync_responses = await llm.async_chat(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmstudiodev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
